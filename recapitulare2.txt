8. LINUX: Check network interface
8. LINUX: Change the directory, go back
1.1 General: Use any and all with sets
1.1 General: Run a UNITTEST
1.3 Numpy: Create an array and filter it's odd values
3. SPARK: Return the first element of a RDD.
1.2 Pandas: Merge two dataframes
1.7 Collections: Create a default dictionary
2. SQL Make a cross join
8. LINUX: Print working directory
1.2 Pandas: Read a .csv file, make correlations between 3 columns
1.2 Pandas: Create a dataframe from a dictionary
9. SKLEARN: Classify some SVM
1.3 Numpy: Create an array and reverse it's collumns and rows
8. LINUX: Copy a file in another directory
6. GIT: Initialize a local git repository
8. LINUX: See last 100 lines
1.1 General: Create a class with dunder __str__, __len__, __del__
8. LINUX: List the opened files
1.1 General: Use super from classes
8. LINUX: Concatenate to a file using cat
1.3 Numpy: Create 2 arrays and stack them h and v ( 3 methods)
8. LINUX: Make a directory in a particular destination
1.2 Pandas: Read a .csv file, print the mean/min/max/median/std
1.1 General: Do one thing two ways and time it
3. SPARK: Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results.
1.7 Datetime: Print the date like: My bday is on April 19, 1994
8. LINUX: Move a file
8. LINUX: See content of a file in real time
6. GIT: How to escape from editing comment
1.7 Random: Roulette: black has 18, red has 18, green has 2, print 5 trials
1.2 Pandas: Read a .csv file, filter by one column name
3. SPARK: Create the main entry point to the spark functionality
6. GIT: Create a ignoring file and check if it works
8. LINUX: Show the network status
2. SQL Make multiple filtering using LIKE
1.1 General: Create 2 classes (inheritance)
1.6 SQLite3: Create a database, a table and the columns
1.2 Pandas: Read a .csv file in chunks (iterative)
2. SQL Insert multiple records in a table
1.1 General: Create a function with args and kwargs
8. LINUX: List all processes page by page
2. SQL Join 2 tables
8. LINUX: Change the directory, go to the root directory
1.2 Pandas: Read a .csv file, delete one column
8. LINUX: Checks the connection with a url
1.1 General: Getting an item from a dictionary without the program yelling at us if it doesn't exist
3. SPARK: Return a new RDD containing only the elements that satisfy a predicate.
1.1 General: Write a number as binary, hexa, and octa
1.6 SQLite3: Use SELECT, INSERT, DELETE and UPDATE
2. SQL Make a natural join
1.1 General: Print 'a','b','c' separated by #
2. SQL Make a union of querries
1.7 Collections: Create a named tuple
1.7 Regex: Search for begining and end of a word character
1.1 General: Make a string iterable
1.2 Pandas: Read a .csv file, use loc and iloc
1.7 Regex: Search for digits, characters
1.2 Pandas: Concatenate two dataframes
8. LINUX: Remove a folder with a file inside
2. SQL Order some elements from a table and print distinct rows
1.3 Numpy: Create an 2x3 array and make it all by one row
1.1 General: Sort 2 objects
8. LINUX: Locate a file
6. GIT: Remove an added file from the index
8. LINUX: List all processes
9. SKLEARN: Classify some data using k-NN
1.2 Pandas: Read a .csv file, group the elements by one column, sorted by another column, mean values
1.1 General: Use enumerate function
8. LINUX: Find a file in a directory
1.2 Pandas: Read a .csv file, view one particular cell
2. SQL Multiple ordering
2. SQL Select rows when a collumn is null
1.2 Pandas: Read a .csv file, iterate through rows
3. SPARK: Return the number of elements in this RDD.
1.1 General: One liner generator
8. LINUX: List all the files in subdirectories
1.2 Pandas: Read a .csv file, use multiple filtering using REGEX
1.1 General: Use polymorphism
8. LINUX: Redo a command using numbers from history
1.2 Pandas: Read a .csv file, reset the index ( 2 ways, inplace)
1.2 Pandas: Read a .csv file, use multiple filtering
1.1 General: Create a generator
1.1 General: Use map
1.2 Pandas: Read a .csv file, view one single column 2 ways
1.7 Datetime: Create a date, get today's date
1.1 General: Round 234.214 as : 230.0 and 234.21
1.1 General: Print all the different elements between two sets
8. LINUX: Checks the permissions
1.1 General: Use lambda
1.3 Numpy: Create an array and print it's max and sum ( total sum, sum for two axis)
1.2 Pandas: Read a .csv file, create a column
1.2 Pandas: Read a .csv file, rename one column
8. LINUX: Create a file using cat
6. GIT: Commit without edditing the comment
1.1 General: Use __name__ __ main__ functions
1.2 Pandas: Join two dataframes
6. GIT: Push to a remote repository
8. LINUX: Make a directory
1.1 General: Create and and delete one folder
1.1 General: Display all .txt files from one folder
1.1 General: Unpack 7 values but use only the 3 values from the middle
3. SPARK: Enter in Spark visualizer
1.1 General: Open big files in chunks
8. LINUX: Make multiple directories
1.2 Pandas: Read a .csv file, view 3 columns
2. SQL Create REGEXP function and use it
2. SQL Join 3 tables
1.2 Pandas: Read a .csv file, sort 2 columns
1.2 Pandas: Read a .csv file, change the value of on column ( napoli -> steaua)
1.1 General: Use zip function
1.2 Pandas: Read a .csv file, print it's tail, head and shape
3. SPARK: Running the spark job
1.3 Numpy: Create an array and print it's square root, standard deviation
8. LINUX: Making shortcuts using alias
8. LINUX: Remove a file
1.3 Numpy: Create an array, print it's dimentsion, itemsize, type, size, shape
1.2 Pandas: Read a .csv file, print it's columns
1.2 Pandas: Read a .csv file, convert the type of one column
1.7 OS: Change directory, remove one directory, use walk to print all the files
1.1 General: Use else statement with while
8. LINUX: Show all users currently on the server
8. LINUX: View a file using cat
8. LINUX: Copy a file in the same directory
1.7 Random: Print a random value between 15 and 19
1.1 General: Using argv
1.2 Pandas: Read a .csv file, save the new csv
6. GIT: Add files to the index (two ways to add all the files)
3. SPARK: Load a file as a RDD using inside range function
3. SPARK: Return the union of this RDD and another one.
3. SPARK: Return all possible pairs of 2 RDDs
1.1 General: Create a comprehensive dictionary
1.7 Collections: Create a dictionary with letters count
8. LINUX: Change the directory, go previous
3. SPARK: Save the rdd to another file
8. LINUX: Show the free space
1.7 Collections: Create an ordered dictionary
1.1 General: Use filter
2. SQL Make an outer join
1.2 Pandas: Read a .csv file, view particular rows
1.2 Pandas: Read a .csv file, fill the NA cells with one value
1.2 Pandas: Read a .csv file, create a column with lambda function
8. LINUX: Restart your pc
1.3 Numpy: Print the common and the different elements between 2 arrays
1.1 General: Add two dictionaries
9. SKLEARN: Make a prediction using linear regression
1.1 General: Print (5, 5) as 0005 5.00000
1.1 General: Create a decorator (logging in)
8. LINUX: Show how much space uses some files
3. SPARK: Enter in Spark shell
1.3 Numpy: Create an array and use Tile
2. SQL Make a subquery using IN
6. GIT: Create and switch to another branch, then merge them
8. LINUX: Remove a directory
1.2 Pandas: Create a series from a list
9. SKLEARN: Group some data using Mean Shift
1.3 Numpy: Create a function which takes x and y and makes it x*3+y*2 and apply it on two arrays
8. LINUX: List the files in directory
1.2 Pandas: Create a dataframe from a 1.3 Numpy array
2. SQL Make operations on and use AS
8. LINUX: Give the execution right (two ways)
1.1 General: Write prime numbers algorithm ( one liner ! )
8. LINUX: Check the internet connectivity
1.3 Numpy: Create an array, using an interval and  [0, 10] and print 6 values between
3. SPARK: Return a new RDD containing the distinct elements in this RDD.
1.1 General: Print all common elements between two sets
1.2 Pandas: Read a .csv file, create a new column which counts the types
3. SPARK: Return samples of a RDD ( 2 ways, elements that can be re-chosen)
1.2 Pandas: Create a series from a list and change the indexing to a, b, c, d
3. SPARK: Return a list that contains all of the elements of a RDD.
8. LINUX: Network connections and status of sockets
3. SPARK: Keeps a RDD in memory for repeated actions
1.2 Pandas: Create a dataframe from a list
1.1 General: Print 1____10 2___100 3__1000 4_10000
1.3 Numpy: Create an array and print it's exponential and logaritmic values
8. LINUX: Show history
3. SPARK: Load a file as a RDD
1.2 Pandas: Create a dataframe from a series
1.1 General: Print the orders of A, F and z characters
1.1 General: Print with % (string and digit)
1.1 General: Create __gt__ and __lt__  and __eq__ functions
6. GIT: Pull from a repository
8. LINUX: Rename a file
9. SKLEARN: Group some data using kMeans
1.1 General: Create a comprehensive dictionary
1.3 Numpy: Create an array and swap it's collumns and rows
1.1 General: Create __add__ and __mul__ functions
2. SQL Copy a table
1.1 General: Use pdb module to debug
1.1 General: Write CMMDC algorithm
6. GIT: Clone a repository
1.1 General: Joining elements of a list with a special character
1.3 Numpy: Create an array, reshape it, slice it ( print only the middle)
2. SQL Join 2 table with same column using 'using'
3. SPARK: Take the first num elements of the RDD.
1.1 General: Print (#, 8) as ___#________*
1.3 Numpy: Create an array and use where
1.1 General: Print a number as 3e2
2. SQL Use SELECT and show only 7 values, skiping the first 5
8. LINUX: Change the directory
